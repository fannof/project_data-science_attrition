{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyek Pertama: Menyelesaikan Permasalahan Perusahaan Jaya Jaya Maju"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nama: Novan Nur Hidayat\n",
    "- Email: novan.nur.hidayat@gmail.com\n",
    "- Id Dicoding: fannof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persiapan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menyiapkan Library yang Dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "from modules.pipeline import init_local_pipeline\n",
    "from modules.components import init_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Menyiapkan Data yang akan Digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeId</th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1444</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1141</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1323</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>555</td>\n",
       "      <td>Sales</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1194</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeId  Age  Attrition     BusinessTravel  DailyRate  \\\n",
       "0           1   38        NaN  Travel_Frequently       1444   \n",
       "1           2   37        1.0      Travel_Rarely       1141   \n",
       "2           3   51        1.0      Travel_Rarely       1323   \n",
       "3           4   42        0.0  Travel_Frequently        555   \n",
       "4           5   40        NaN      Travel_Rarely       1194   \n",
       "\n",
       "               Department  DistanceFromHome  Education EducationField  \\\n",
       "0         Human Resources                 1          4          Other   \n",
       "1  Research & Development                11          2        Medical   \n",
       "2  Research & Development                 4          4  Life Sciences   \n",
       "3                   Sales                26          3      Marketing   \n",
       "4  Research & Development                 2          4        Medical   \n",
       "\n",
       "   EmployeeCount  ...  RelationshipSatisfaction StandardHours  \\\n",
       "0              1  ...                         2            80   \n",
       "1              1  ...                         1            80   \n",
       "2              1  ...                         3            80   \n",
       "3              1  ...                         4            80   \n",
       "4              1  ...                         2            80   \n",
       "\n",
       "   StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                 1                  7                      2               3   \n",
       "1                 0                 15                      2               1   \n",
       "2                 3                 18                      2               4   \n",
       "3                 1                 23                      2               4   \n",
       "4                 3                 20                      2               3   \n",
       "\n",
       "   YearsAtCompany YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0               6                  2                        1   \n",
       "1               1                  0                        0   \n",
       "2              10                  0                        2   \n",
       "3              20                  4                        4   \n",
       "4               5                  3                        0   \n",
       "\n",
       "   YearsWithCurrManager  \n",
       "0                     2  \n",
       "1                     0  \n",
       "2                     7  \n",
       "3                     8  \n",
       "4                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/employee_data.csv\")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column Name                | Description                                        |\n",
    "|----------------------------|----------------------------------------------------|\n",
    "| EmployeeId                 | Employee Identifier                                |\n",
    "| Attrition                  | Did the employee attrition? (0=no, 1=yes)          |\n",
    "| Age                        | Age of the employee                                |\n",
    "| BusinessTravel             | Travel commitments for the job                     |\n",
    "| DailyRate                  | Daily salary                                       |\n",
    "| Department                 | Employee Department                               |\n",
    "| DistanceFromHome           | Distance from work to home (in km)                 |\n",
    "| Education                  | 1-Below College, 2-College, 3-Bachelor, 4-Master, 5-Doctor |\n",
    "| EducationField             | Field of Education                                |\n",
    "| EnvironmentSatisfaction    | 1-Low, 2-Medium, 3-High, 4-Very High               |\n",
    "| Gender                     | Employee's gender                                  |\n",
    "| HourlyRate                 | Hourly salary                                      |\n",
    "| JobInvolvement             | 1-Low, 2-Medium, 3-High, 4-Very High               |\n",
    "| JobLevel                   | Level of job (1 to 5)                              |\n",
    "| JobRole                    | Job Roles                                          |\n",
    "| JobSatisfaction            | 1-Low, 2-Medium, 3-High, 4-Very High               |\n",
    "| MaritalStatus              | Marital Status                                     |\n",
    "| MonthlyIncome              | Monthly salary                                     |\n",
    "| MonthlyRate                | Monthly rate                                       |\n",
    "| NumCompaniesWorked         | Number of companies worked at                      |\n",
    "| Over18                     | Over 18 years of age?                              |\n",
    "| OverTime                   | Overtime?                                          |\n",
    "| PercentSalaryHike          | The percentage increase in salary last year        |\n",
    "| PerformanceRating          | 1-Low, 2-Good, 3-Excellent, 4-Outstanding           |\n",
    "| RelationshipSatisfaction   | 1-Low, 2-Medium, 3-High, 4-Very High               |\n",
    "| StandardHours              | Standard Hours                                     |\n",
    "| StockOptionLevel           | Stock Option Level                                 |\n",
    "| TotalWorkingYears          | Total years worked                                |\n",
    "| TrainingTimesLastYear      | Number of training attended last year              |\n",
    "| WorkLifeBalance            | 1-Low, 2-Good, 3-Excellent, 4-Outstanding           |\n",
    "| YearsAtCompany             | Years at Company                                   |\n",
    "| YearsInCurrentRole         | Years in the current role                          |\n",
    "| YearsSinceLastPromotion    | Years since the last promotion                     |\n",
    "| YearsWithCurrManager       | Years with the current manager                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset berisi data karyawan dengan 35 kolom, dengan atribut seperti dibawah ini:\n",
    "\n",
    "- Demografis: Age, Gender, MaritalStatus, EducationField, Department\n",
    "- Performa: JobLevel, PerformanceRating, TotalWorkingYears\n",
    "- Penghasilan: MonthlyIncome, PercentSalaryHike\n",
    "- Work-Life: OverTime, WorkLifeBalance, YearsAtCompany\n",
    "- Satisfaction: JobSatisfaction, RelationshipSatisfaction, EnvironmentSatisfaction\n",
    "- Mobilitas: BusinessTravel, DistanceFromHome, NumCompaniesWorked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   EmployeeId                1470 non-null   int64  \n",
      " 1   Age                       1470 non-null   int64  \n",
      " 2   Attrition                 1058 non-null   float64\n",
      " 3   BusinessTravel            1470 non-null   object \n",
      " 4   DailyRate                 1470 non-null   int64  \n",
      " 5   Department                1470 non-null   object \n",
      " 6   DistanceFromHome          1470 non-null   int64  \n",
      " 7   Education                 1470 non-null   int64  \n",
      " 8   EducationField            1470 non-null   object \n",
      " 9   EmployeeCount             1470 non-null   int64  \n",
      " 10  EnvironmentSatisfaction   1470 non-null   int64  \n",
      " 11  Gender                    1470 non-null   object \n",
      " 12  HourlyRate                1470 non-null   int64  \n",
      " 13  JobInvolvement            1470 non-null   int64  \n",
      " 14  JobLevel                  1470 non-null   int64  \n",
      " 15  JobRole                   1470 non-null   object \n",
      " 16  JobSatisfaction           1470 non-null   int64  \n",
      " 17  MaritalStatus             1470 non-null   object \n",
      " 18  MonthlyIncome             1470 non-null   int64  \n",
      " 19  MonthlyRate               1470 non-null   int64  \n",
      " 20  NumCompaniesWorked        1470 non-null   int64  \n",
      " 21  Over18                    1470 non-null   object \n",
      " 22  OverTime                  1470 non-null   object \n",
      " 23  PercentSalaryHike         1470 non-null   int64  \n",
      " 24  PerformanceRating         1470 non-null   int64  \n",
      " 25  RelationshipSatisfaction  1470 non-null   int64  \n",
      " 26  StandardHours             1470 non-null   int64  \n",
      " 27  StockOptionLevel          1470 non-null   int64  \n",
      " 28  TotalWorkingYears         1470 non-null   int64  \n",
      " 29  TrainingTimesLastYear     1470 non-null   int64  \n",
      " 30  WorkLifeBalance           1470 non-null   int64  \n",
      " 31  YearsAtCompany            1470 non-null   int64  \n",
      " 32  YearsInCurrentRole        1470 non-null   int64  \n",
      " 33  YearsSinceLastPromotion   1470 non-null   int64  \n",
      " 34  YearsWithCurrManager      1470 non-null   int64  \n",
      "dtypes: float64(1), int64(26), object(8)\n",
      "memory usage: 402.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmployeeId                    0\n",
      "Age                           0\n",
      "Attrition                   412\n",
      "BusinessTravel                0\n",
      "DailyRate                     0\n",
      "Department                    0\n",
      "DistanceFromHome              0\n",
      "Education                     0\n",
      "EducationField                0\n",
      "EmployeeCount                 0\n",
      "EnvironmentSatisfaction       0\n",
      "Gender                        0\n",
      "HourlyRate                    0\n",
      "JobInvolvement                0\n",
      "JobLevel                      0\n",
      "JobRole                       0\n",
      "JobSatisfaction               0\n",
      "MaritalStatus                 0\n",
      "MonthlyIncome                 0\n",
      "MonthlyRate                   0\n",
      "NumCompaniesWorked            0\n",
      "Over18                        0\n",
      "OverTime                      0\n",
      "PercentSalaryHike             0\n",
      "PerformanceRating             0\n",
      "RelationshipSatisfaction      0\n",
      "StandardHours                 0\n",
      "StockOptionLevel              0\n",
      "TotalWorkingYears             0\n",
      "TrainingTimesLastYear         0\n",
      "WorkLifeBalance               0\n",
      "YearsAtCompany                0\n",
      "YearsInCurrentRole            0\n",
      "YearsSinceLastPromotion       0\n",
      "YearsWithCurrManager          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terdapat misssing value sebanyak 412 data pada kolom Attrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidak ada data duplikat dalam dataset ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BusinessTravel: \n",
      " ['Travel_Frequently' 'Travel_Rarely' 'Non-Travel'] \n",
      "\n",
      "Department: \n",
      " ['Human Resources' 'Research & Development' 'Sales'] \n",
      "\n",
      "EducationField: \n",
      " ['Other' 'Medical' 'Life Sciences' 'Marketing' 'Technical Degree'\n",
      " 'Human Resources'] \n",
      "\n",
      "Gender: \n",
      " ['Male' 'Female'] \n",
      "\n",
      "JobRole: \n",
      " ['Human Resources' 'Healthcare Representative' 'Research Scientist'\n",
      " 'Sales Executive' 'Manager' 'Laboratory Technician' 'Research Director'\n",
      " 'Manufacturing Director' 'Sales Representative'] \n",
      "\n",
      "MaritalStatus: \n",
      " ['Married' 'Single' 'Divorced'] \n",
      "\n",
      "Over18: \n",
      " ['Y'] \n",
      "\n",
      "OverTime: \n",
      " ['Yes' 'No'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "for column in categorical_columns:\n",
    "    unique_values = df[column].unique()\n",
    "    print(f\"{column}: \\n {unique_values}\", '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut merupakan kolom kategori beserta jenis dari kolom tersebut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeId</th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>1470</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.0</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "      <td>1470.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>735.500000</td>\n",
       "      <td>36.923810</td>\n",
       "      <td>0.169187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>802.485714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.192517</td>\n",
       "      <td>2.912925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.712245</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.793878</td>\n",
       "      <td>11.279592</td>\n",
       "      <td>2.799320</td>\n",
       "      <td>2.761224</td>\n",
       "      <td>7.008163</td>\n",
       "      <td>4.229252</td>\n",
       "      <td>2.187755</td>\n",
       "      <td>4.123129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>424.496761</td>\n",
       "      <td>9.135373</td>\n",
       "      <td>0.375094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>403.509100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.106864</td>\n",
       "      <td>1.024165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.081209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.852077</td>\n",
       "      <td>7.780782</td>\n",
       "      <td>1.289271</td>\n",
       "      <td>0.706476</td>\n",
       "      <td>6.126525</td>\n",
       "      <td>3.623137</td>\n",
       "      <td>3.222430</td>\n",
       "      <td>3.568136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>368.250000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>465.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>735.500000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1102.750000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1157.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1470.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1499.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         EmployeeId          Age    Attrition BusinessTravel    DailyRate  \\\n",
       "count   1470.000000  1470.000000  1058.000000           1470  1470.000000   \n",
       "unique          NaN          NaN          NaN              3          NaN   \n",
       "top             NaN          NaN          NaN  Travel_Rarely          NaN   \n",
       "freq            NaN          NaN          NaN           1043          NaN   \n",
       "mean     735.500000    36.923810     0.169187            NaN   802.485714   \n",
       "std      424.496761     9.135373     0.375094            NaN   403.509100   \n",
       "min        1.000000    18.000000     0.000000            NaN   102.000000   \n",
       "25%      368.250000    30.000000     0.000000            NaN   465.000000   \n",
       "50%      735.500000    36.000000     0.000000            NaN   802.000000   \n",
       "75%     1102.750000    43.000000     0.000000            NaN  1157.000000   \n",
       "max     1470.000000    60.000000     1.000000            NaN  1499.000000   \n",
       "\n",
       "                    Department  DistanceFromHome    Education EducationField  \\\n",
       "count                     1470       1470.000000  1470.000000           1470   \n",
       "unique                       3               NaN          NaN              6   \n",
       "top     Research & Development               NaN          NaN  Life Sciences   \n",
       "freq                       961               NaN          NaN            606   \n",
       "mean                       NaN          9.192517     2.912925            NaN   \n",
       "std                        NaN          8.106864     1.024165            NaN   \n",
       "min                        NaN          1.000000     1.000000            NaN   \n",
       "25%                        NaN          2.000000     2.000000            NaN   \n",
       "50%                        NaN          7.000000     3.000000            NaN   \n",
       "75%                        NaN         14.000000     4.000000            NaN   \n",
       "max                        NaN         29.000000     5.000000            NaN   \n",
       "\n",
       "        EmployeeCount  ...  RelationshipSatisfaction StandardHours  \\\n",
       "count          1470.0  ...               1470.000000        1470.0   \n",
       "unique            NaN  ...                       NaN           NaN   \n",
       "top               NaN  ...                       NaN           NaN   \n",
       "freq              NaN  ...                       NaN           NaN   \n",
       "mean              1.0  ...                  2.712245          80.0   \n",
       "std               0.0  ...                  1.081209           0.0   \n",
       "min               1.0  ...                  1.000000          80.0   \n",
       "25%               1.0  ...                  2.000000          80.0   \n",
       "50%               1.0  ...                  3.000000          80.0   \n",
       "75%               1.0  ...                  4.000000          80.0   \n",
       "max               1.0  ...                  4.000000          80.0   \n",
       "\n",
       "        StockOptionLevel  TotalWorkingYears  TrainingTimesLastYear  \\\n",
       "count        1470.000000        1470.000000            1470.000000   \n",
       "unique               NaN                NaN                    NaN   \n",
       "top                  NaN                NaN                    NaN   \n",
       "freq                 NaN                NaN                    NaN   \n",
       "mean            0.793878          11.279592               2.799320   \n",
       "std             0.852077           7.780782               1.289271   \n",
       "min             0.000000           0.000000               0.000000   \n",
       "25%             0.000000           6.000000               2.000000   \n",
       "50%             1.000000          10.000000               3.000000   \n",
       "75%             1.000000          15.000000               3.000000   \n",
       "max             3.000000          40.000000               6.000000   \n",
       "\n",
       "       WorkLifeBalance  YearsAtCompany YearsInCurrentRole  \\\n",
       "count      1470.000000     1470.000000        1470.000000   \n",
       "unique             NaN             NaN                NaN   \n",
       "top                NaN             NaN                NaN   \n",
       "freq               NaN             NaN                NaN   \n",
       "mean          2.761224        7.008163           4.229252   \n",
       "std           0.706476        6.126525           3.623137   \n",
       "min           1.000000        0.000000           0.000000   \n",
       "25%           2.000000        3.000000           2.000000   \n",
       "50%           3.000000        5.000000           3.000000   \n",
       "75%           3.000000        9.000000           7.000000   \n",
       "max           4.000000       40.000000          18.000000   \n",
       "\n",
       "        YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "count               1470.000000           1470.000000  \n",
       "unique                      NaN                   NaN  \n",
       "top                         NaN                   NaN  \n",
       "freq                        NaN                   NaN  \n",
       "mean                   2.187755              4.123129  \n",
       "std                    3.222430              3.568136  \n",
       "min                    0.000000              0.000000  \n",
       "25%                    0.000000              2.000000  \n",
       "50%                    1.000000              3.000000  \n",
       "75%                    3.000000              7.000000  \n",
       "max                   15.000000             17.000000  \n",
       "\n",
       "[11 rows x 35 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan deskriptif statistik pada tabel diatas, dapat disimpulkan:\n",
    "- Terdapat 1.470 karyawan (jumlah total data pada kolom EmployeeId).\n",
    "- Rata-rata usia karyawan adalah 36,92 tahun, dengan usia termuda 18 tahun dan usia tertua 60 tahun, 25% karyawan berusia 30 tahun atau lebih muda, dan 25% lainnya berusia 43 tahun atau lebih tua.\n",
    "- Rata-rata gaji harian karyawan adalah 802,49 dolar, gaji harian terendah adalah 102, sedangkan tertinggi mencapai 1.499, 50% karyawan memiliki gaji harian di bawah 802.\n",
    "- Rata-rata jarak dari rumah ke tempat kerja adalah 9,19 km, jarak terpendek adalah 1 km, sedangkan terjauh adalah 29 km.\n",
    "- Rata-rata tingkat pendidikan karyawan adalah 2,91, menunjukkan bahwa kebanyakan karyawan memiliki gelar College atau Bachelor.\n",
    "- Karyawan memiliki pengalaman kerja yang bervariasi, mulai dari 0 hingga 40 tahun, rata-rata total tahun bekerja adalah 11,28 tahun dan 50% karyawan telah bekerja selama 10 tahun atau kurang.\n",
    "- Skala 1 hingga 4 digunakan untuk mengukur keseimbangan antara kehidupan dan pekerjaan, dengan rata-rata 2,76 (sekitar \"Good\"). Kebanyakan karyawan memiliki keseimbangan kerja yang baik.\n",
    "- Rata-rata masa kerja di perusahaan saat ini adalah 7 tahun, dengan masa terlama 40 tahun dan terpendek 0 tahun. 50% karyawan telah bekerja di perusahaan selama 5 tahun atau kurang.\n",
    "- Skala 1 hingga 4 digunakan untuk mengukur kepuasan kerja, dengan rata-rata 2,71 (sekitar \"Medium\"). Mayoritas karyawan memiliki kepuasan kerja di tingkat sedang atau tinggi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation / Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengubah nilai numerik yang seharusnya berisi nilai kategorik agar lebih mudah dipahami untuk pemrosesan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Education'] = df['Education'].replace({1 : 'Below College', 2 : 'College', 3 : 'Bachelor', 4 : 'Master', 5 : 'Doctor'})\n",
    "df['EnvironmentSatisfaction'] = df['EnvironmentSatisfaction'].replace({1 : 'Low', 2 : 'Medium', 3 : 'High', 4 : 'Very High'})\n",
    "df['JobInvolvement'] = df['JobInvolvement'].replace({1 : 'Low', 2 : 'Medium', 3 : 'High', 4 : 'Very High'})\n",
    "df['JobSatisfaction'] = df['JobSatisfaction'].replace({1 : 'Low', 2 : 'Medium', 3 : 'High', 4 : 'Very High'})\n",
    "df['PerformanceRating'] = df['PerformanceRating'].replace({1 : 'Low', 2 : 'Good', 3 : 'Excellent', 4 : 'Outstanding'})\n",
    "df['RelationshipSatisfaction'] = df['RelationshipSatisfaction'].replace({1 : 'Low', 2 : 'Medium', 3 : 'High', 4 : 'Very High'})\n",
    "df['WorkLifeBalance'] = df['WorkLifeBalance'].replace({1 : 'Low', 2 : 'Good', 3 : 'Excellent', 4 : 'Outstanding'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengisi nilai missing value di kolom Attrition dengan nilai yang paling banyak muncul(modus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mode = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   EmployeeId                1470 non-null   int64  \n",
      " 1   Age                       1470 non-null   int64  \n",
      " 2   Attrition                 1470 non-null   float64\n",
      " 3   BusinessTravel            1470 non-null   object \n",
      " 4   DailyRate                 1470 non-null   int64  \n",
      " 5   Department                1470 non-null   object \n",
      " 6   DistanceFromHome          1470 non-null   int64  \n",
      " 7   Education                 1470 non-null   object \n",
      " 8   EducationField            1470 non-null   object \n",
      " 9   EmployeeCount             1470 non-null   int64  \n",
      " 10  EnvironmentSatisfaction   1470 non-null   object \n",
      " 11  Gender                    1470 non-null   object \n",
      " 12  HourlyRate                1470 non-null   int64  \n",
      " 13  JobInvolvement            1470 non-null   object \n",
      " 14  JobLevel                  1470 non-null   int64  \n",
      " 15  JobRole                   1470 non-null   object \n",
      " 16  JobSatisfaction           1470 non-null   object \n",
      " 17  MaritalStatus             1470 non-null   object \n",
      " 18  MonthlyIncome             1470 non-null   int64  \n",
      " 19  MonthlyRate               1470 non-null   int64  \n",
      " 20  NumCompaniesWorked        1470 non-null   int64  \n",
      " 21  Over18                    1470 non-null   object \n",
      " 22  OverTime                  1470 non-null   object \n",
      " 23  PercentSalaryHike         1470 non-null   int64  \n",
      " 24  PerformanceRating         1470 non-null   object \n",
      " 25  RelationshipSatisfaction  1470 non-null   object \n",
      " 26  StandardHours             1470 non-null   int64  \n",
      " 27  StockOptionLevel          1470 non-null   int64  \n",
      " 28  TotalWorkingYears         1470 non-null   int64  \n",
      " 29  TrainingTimesLastYear     1470 non-null   int64  \n",
      " 30  WorkLifeBalance           1470 non-null   object \n",
      " 31  YearsAtCompany            1470 non-null   int64  \n",
      " 32  YearsInCurrentRole        1470 non-null   int64  \n",
      " 33  YearsSinceLastPromotion   1470 non-null   int64  \n",
      " 34  YearsWithCurrManager      1470 non-null   int64  \n",
      "dtypes: float64(1), int64(19), object(15)\n",
      "memory usage: 402.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "attrition_mode = df_mode['Attrition'].mode()[0]\n",
    "df_mode['Attrition'].fillna(attrition_mode, inplace=True)\n",
    "\n",
    "print(df_mode.info())\n",
    "\n",
    "df_mode.to_csv('dataset/employee_data_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang sudah tidak ada missing value karena sudah diisi dengan nilai terbanyak(modus) dan menyimpan sebagai dataset baru bernama employee_data_clean.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeId</th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EmployeeCount</th>\n",
       "      <th>...</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StandardHours</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>1444</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>1</td>\n",
       "      <td>Master</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1141</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>11</td>\n",
       "      <td>College</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1323</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>4</td>\n",
       "      <td>Master</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>Outstanding</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>555</td>\n",
       "      <td>Sales</td>\n",
       "      <td>26</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Very High</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>Outstanding</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>1194</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>Master</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Medium</td>\n",
       "      <td>80</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EmployeeId  Age  Attrition     BusinessTravel  DailyRate  \\\n",
       "0           1   38        0.0  Travel_Frequently       1444   \n",
       "1           2   37        1.0      Travel_Rarely       1141   \n",
       "2           3   51        1.0      Travel_Rarely       1323   \n",
       "3           4   42        0.0  Travel_Frequently        555   \n",
       "4           5   40        0.0      Travel_Rarely       1194   \n",
       "\n",
       "               Department  DistanceFromHome Education EducationField  \\\n",
       "0         Human Resources                 1    Master          Other   \n",
       "1  Research & Development                11   College        Medical   \n",
       "2  Research & Development                 4    Master  Life Sciences   \n",
       "3                   Sales                26  Bachelor      Marketing   \n",
       "4  Research & Development                 2    Master        Medical   \n",
       "\n",
       "   EmployeeCount  ... RelationshipSatisfaction StandardHours  \\\n",
       "0              1  ...                   Medium            80   \n",
       "1              1  ...                      Low            80   \n",
       "2              1  ...                     High            80   \n",
       "3              1  ...                Very High            80   \n",
       "4              1  ...                   Medium            80   \n",
       "\n",
       "   StockOptionLevel TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                 1                 7                      2       Excellent   \n",
       "1                 0                15                      2             Low   \n",
       "2                 3                18                      2     Outstanding   \n",
       "3                 1                23                      2     Outstanding   \n",
       "4                 3                20                      2       Excellent   \n",
       "\n",
       "  YearsAtCompany YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0              6                  2                        1   \n",
       "1              1                  0                        0   \n",
       "2             10                  0                        2   \n",
       "3             20                  4                        4   \n",
       "4              5                  3                        0   \n",
       "\n",
       "   YearsWithCurrManager  \n",
       "0                     2  \n",
       "1                     0  \n",
       "2                     7  \n",
       "3                     8  \n",
       "4                     2  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mode.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arsitektur ini adalah model klasifikasi biner berbasis jaringan saraf sederhana dengan tiga lapisan tersembunyi yang menggunakan fungsi aktivasi ReLU, diakhiri dengan satu neuron keluaran dengan fungsi aktivasi sigmoid. Model ini dirancang untuk mengklasifikasikan apakah seorang karyawan akan mengalami attrition (berhenti bekerja) atau tidak, berdasarkan fitur-fitur yang diberikan. Lapisannya adalah sebagai berikut:\n",
    "- Lapisan pertama yaitu tf.keras.layers.Dense(256, activation=\"relu\")(concatenate) memiliki 256 neuron dengan fungsi aktivasi ReLU (Rectified Linear Unit), yang bertujuan untuk menambahkan kompleksitas ke model dan menangkap pola-pola non-linear dari data.\n",
    "- Lapisan kedua yaitu tf.keras.layers.Dense(64, activation=\"relu\")(deep) memiliki 64 neuron, juga menggunakan fungsi aktivasi ReLU, yang membantu memperdalam jaringan dan membuatnya lebih mampu mengenali pola yang lebih kompleks.\n",
    "- Lapisan ketiga yaitu tf.keras.layers.Dense(16, activation=\"relu\")(deep) memiliki 16 neuron, juga menggunakan ReLU. Ini adalah lapisan akhir dari hidden layer, berfungsi untuk semakin menyederhanakan representasi data yang telah dipelajari.\n",
    "- outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(deep) adalah lapisan keluaran yang memiliki 1 neuron dengan fungsi aktivasi sigmoid. Fungsi sigmoid menghasilkan nilai antara 0 dan 1, yang sangat cocok untuk masalah klasifikasi biner seperti prediksi apakah seorang karyawan akan berhenti (attrition = 1) atau tetap bekerja (attrition = 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model menggunakan Adam optimizer dengan laju pembelajaran 0,001. Optimizer ini adalah metode yang umum digunakan untuk mempercepat dan meningkatkan proses pelatihan jaringan saraf. Binary Crossentropy digunakan sebagai fungsi kerugian karena ini adalah masalah klasifikasi biner. Fungsi ini mengukur perbedaan antara nilai prediksi (dari fungsi sigmoid) dan nilai sebenarnya (0 atau 1). BinaryAccuracy digunakan sebagai metrik untuk memantau kinerja model selama pelatihan. Ini menghitung seberapa sering prediksi model benar (prediksi yang lebih besar dari 0,5 dianggap 1, dan yang lebih kecil dari 0,5 dianggap 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'attrition-pipeline'\n",
    "\n",
    "DATA_ROOT = 'dataset'\n",
    "TRANSFORM_MODULE_FILE = 'modules/transform.py'\n",
    "TRAINER_MODULE_FILE = 'modules/trainer.py'\n",
    "\n",
    "OUTPUT_BASE = 'output'\n",
    "serving_model_dir = os.path.join(OUTPUT_BASE, 'serving_model')\n",
    "pipeline_root = os.path.join(OUTPUT_BASE, PIPELINE_NAME)\n",
    "metadata_path = os.path.join(pipeline_root, 'metadata.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk arsitektur model lebih lengkap berada di folder modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilai binary crossentropy loss pada data validasi yang cukup besar (2.2117) menunjukkan bahwa model tidak memprediksi dengan baik pada data validasi, berbeda jauh dari hasil pada data pelatihan. Hal ini mengindikasikan bahwa model mungkin mengalami overfitting, yaitu terlalu baik dalam menghafal data pelatihan namun tidak mampu menggeneralisasi dengan baik pada data baru.\n",
    "\n",
    "\n",
    "Akurasi pada data validasi adalah 88.65%, yang berarti model berhasil memprediksi sekitar 88.65% dari data validasi dengan benar. Meskipun lebih rendah dari akurasi pada data pelatihan, angka ini masih menunjukkan performa yang cukup baik pada data yang belum pernah dilihat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607315   nanos: 378223180 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607315   nanos: 386539936 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607315   nanos: 590335369 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607315   nanos: 523725032 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607315   nanos: 676264286 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607315   nanos: 666690826 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607316   nanos: 122714996 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607316   nanos: 99936962 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607332   nanos: 603437423 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_26\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607332   nanos: 603437423 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_29\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607332   nanos: 634707212 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_27\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-10\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607332   nanos: 680825233 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_28\" transform_id: \"WriteSplit[train]/Write/Write/WriteImpl/WriteBundles\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-13\" \n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607371   nanos: 664177417 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607371   nanos: 711054801 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607371   nanos: 664177417 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607371   nanos: 679802179 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607371   nanos: 664177417 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607371   nanos: 711054801 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607371   nanos: 784383773 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607371   nanos: 846885919 } message: \"Discarding unparseable args: [\\'--direct_runner_use_stacked_bundle\\', \\'--pipeline_type_check\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607382   nanos: 963164329 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_84\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607382   nanos: 963164329 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_83\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607382   nanos: 963164329 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_86\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607382   nanos: 994413375 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_85\" transform_id: \"TFXIORead[train]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\envs\\mlops-attrition\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\envs\\mlops-attrition\\lib\\site-packages\\tensorflow_transform\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_5/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_6/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_7/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_8/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_9/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_10/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_11/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_12/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_13/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_5/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_6/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_7/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_8/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_9/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_10/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_11/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_12/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_13/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607481   nanos: 671322107 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607481   nanos: 686965942 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607481   nanos: 702593326 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607481   nanos: 736996650 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607481   nanos: 834640502 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607481   nanos: 897138118 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607482   nanos: 197839260 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607482   nanos: 275970697 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607491   nanos: 165474653 } message: \"From C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow_transform\\\\tf_utils.py:325: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\\nInstructions for updating:\\nUse ref() instead.\" instruction_id: \"bundle_254\" transform_id: \"Analyze/CreateSavedModelForAnalyzerInputs[Phase0][tf_v2_only]/CreateSavedModel\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\util\\\\deprecation.py:350\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607528   nanos: 811433553 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_606\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-13\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607528   nanos: 858310937 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_609\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607528   nanos: 889558792 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_608\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-10\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729607528   nanos: 905179738 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_607\" transform_id: \"TFXIOReadAndDecode[AnalysisIndex0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " BusinessTravel_xf (InputLayer)  [(None, 4)]         0           []                               \n",
      "                                                                                                  \n",
      " Department_xf (InputLayer)     [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " Education_xf (InputLayer)      [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " EducationField_xf (InputLayer)  [(None, 7)]         0           []                               \n",
      "                                                                                                  \n",
      " EnvironmentSatisfaction_xf (In  [(None, 5)]         0           []                               \n",
      " putLayer)                                                                                        \n",
      "                                                                                                  \n",
      " Gender_xf (InputLayer)         [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " JobInvolvement_xf (InputLayer)  [(None, 5)]         0           []                               \n",
      "                                                                                                  \n",
      " JobRole_xf (InputLayer)        [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " JobSatisfaction_xf (InputLayer  [(None, 5)]         0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " MaritalStatus_xf (InputLayer)  [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " OverTime_xf (InputLayer)       [(None, 3)]          0           []                               \n",
      "                                                                                                  \n",
      " PerformanceRating_xf (InputLay  [(None, 5)]         0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " RelationshipSatisfaction_xf (I  [(None, 5)]         0           []                               \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " WorkLifeBalance_xf (InputLayer  [(None, 5)]         0           []                               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " Age_xf (InputLayer)            [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " DailyRate_xf (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " DistanceFromHome_xf (InputLaye  [(None, 1)]         0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " HourlyRate_xf (InputLayer)     [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " JobLevel_xf (InputLayer)       [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " MonthlyIncome_xf (InputLayer)  [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " MonthlyRate_xf (InputLayer)    [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " NumCompaniesWorked_xf (InputLa  [(None, 1)]         0           []                               \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " PercentSalaryHike_xf (InputLay  [(None, 1)]         0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " StandardHours_xf (InputLayer)  [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " StockOptionLevel_xf (InputLaye  [(None, 1)]         0           []                               \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " TotalWorkingYears_xf (InputLay  [(None, 1)]         0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " TrainingTimesLastYear_xf (Inpu  [(None, 1)]         0           []                               \n",
      " tLayer)                                                                                          \n",
      "                                                                                                  \n",
      " YearsAtCompany_xf (InputLayer)  [(None, 1)]         0           []                               \n",
      "                                                                                                  \n",
      " YearsInCurrentRole_xf (InputLa  [(None, 1)]         0           []                               \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " YearsSinceLastPromotion_xf (In  [(None, 1)]         0           []                               \n",
      " putLayer)                                                                                        \n",
      "                                                                                                  \n",
      " YearsWithCurrManager_xf (Input  [(None, 1)]         0           []                               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 88)           0           ['BusinessTravel_xf[0][0]',      \n",
      "                                                                  'Department_xf[0][0]',          \n",
      "                                                                  'Education_xf[0][0]',           \n",
      "                                                                  'EducationField_xf[0][0]',      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'EnvironmentSatisfaction_xf[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'Gender_xf[0][0]',              \n",
      "                                                                  'JobInvolvement_xf[0][0]',      \n",
      "                                                                  'JobRole_xf[0][0]',             \n",
      "                                                                  'JobSatisfaction_xf[0][0]',     \n",
      "                                                                  'MaritalStatus_xf[0][0]',       \n",
      "                                                                  'OverTime_xf[0][0]',            \n",
      "                                                                  'PerformanceRating_xf[0][0]',   \n",
      "                                                                  'RelationshipSatisfaction_xf[0][\n",
      "                                                                 0]',                             \n",
      "                                                                  'WorkLifeBalance_xf[0][0]',     \n",
      "                                                                  'Age_xf[0][0]',                 \n",
      "                                                                  'DailyRate_xf[0][0]',           \n",
      "                                                                  'DistanceFromHome_xf[0][0]',    \n",
      "                                                                  'HourlyRate_xf[0][0]',          \n",
      "                                                                  'JobLevel_xf[0][0]',            \n",
      "                                                                  'MonthlyIncome_xf[0][0]',       \n",
      "                                                                  'MonthlyRate_xf[0][0]',         \n",
      "                                                                  'NumCompaniesWorked_xf[0][0]',  \n",
      "                                                                  'PercentSalaryHike_xf[0][0]',   \n",
      "                                                                  'StandardHours_xf[0][0]',       \n",
      "                                                                  'StockOptionLevel_xf[0][0]',    \n",
      "                                                                  'TotalWorkingYears_xf[0][0]',   \n",
      "                                                                  'TrainingTimesLastYear_xf[0][0]'\n",
      "                                                                 , 'YearsAtCompany_xf[0][0]',     \n",
      "                                                                  'YearsInCurrentRole_xf[0][0]',  \n",
      "                                                                  'YearsSinceLastPromotion_xf[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'YearsWithCurrManager_xf[0][0]']\n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          22784       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64)           16448       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           1040        ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            17          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 40,289\n",
      "Trainable params: 40,289\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0139 - binary_accuracy: 0.9950 - val_loss: 1.3099 - val_binary_accuracy: 0.8828\n",
      "Epoch 2/10\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 5.1528e-07 - binary_accuracy: 1.0000 - val_loss: 1.5975 - val_binary_accuracy: 0.8865\n",
      "Epoch 3/10\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 2.6902e-08 - binary_accuracy: 1.0000 - val_loss: 1.8232 - val_binary_accuracy: 0.8865\n",
      "Epoch 4/10\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 3.8155e-09 - binary_accuracy: 1.0000 - val_loss: 1.9629 - val_binary_accuracy: 0.8901\n",
      "Epoch 5/10\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 2.5926e-09 - binary_accuracy: 1.0000 - val_loss: 2.0524 - val_binary_accuracy: 0.8865\n",
      "Epoch 6/10\n",
      "5000/5000 [==============================] - 45s 9ms/step - loss: 2.3460e-09 - binary_accuracy: 1.0000 - val_loss: 2.1191 - val_binary_accuracy: 0.8865\n",
      "Epoch 7/10\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 2.2773e-09 - binary_accuracy: 1.0000 - val_loss: 2.1562 - val_binary_accuracy: 0.8864\n",
      "Epoch 8/10\n",
      "5000/5000 [==============================] - 44s 9ms/step - loss: 2.2842e-09 - binary_accuracy: 1.0000 - val_loss: 2.1824 - val_binary_accuracy: 0.8864\n",
      "Epoch 9/10\n",
      "5000/5000 [==============================] - 46s 9ms/step - loss: 2.2581e-09 - binary_accuracy: 1.0000 - val_loss: 2.2020 - val_binary_accuracy: 0.8864\n",
      "Epoch 10/10\n",
      "5000/5000 [==============================] - 45s 9ms/step - loss: 2.2187e-09 - binary_accuracy: 1.0000 - val_loss: 2.2117 - val_binary_accuracy: 0.8865\n",
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: output\\attrition-pipeline\\Trainer\\model\\7\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: output\\attrition-pipeline\\Trainer\\model\\7\\Format-Serving\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000209B6431D90> and <keras.engine.input_layer.InputLayer object at 0x00000209B78402B0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000209B6431D90> and <keras.engine.input_layer.InputLayer object at 0x00000209B78402B0>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000209B3E02730> and <keras.engine.input_layer.InputLayer object at 0x00000209B7EBE1C0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000209B3E02730> and <keras.engine.input_layer.InputLayer object at 0x00000209B7EBE1C0>).\n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608208   nanos: 881920337 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608208   nanos: 976917505 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608208   nanos: 880917549 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608208   nanos: 954917430 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608208   nanos: 896922588 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608209   nanos: 45922040 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608209   nanos: 42922019 } message: \"No semi_persistent_directory found: Functions defined in __main__ (interactive session) may fail.\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\runners\\\\worker\\\\sdk_worker_main.py:332\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608209   nanos: 224281072 } message: \"Discarding unparseable args: [\\'--pipeline_type_check\\', \\'--direct_runner_use_stacked_bundle\\']\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\options\\\\pipeline_options.py:352\" thread: \"MainThread\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608230   nanos: 38030385 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000027297BC5CA0> and <keras.engine.input_layer.InputLayer object at 0x0000027297AEB550>).\" instruction_id: \"bundle_1991\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608230   nanos: 80023765 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001DDFD8F7610> and <keras.engine.input_layer.InputLayer object at 0x000001DDFD823BB0>).\" instruction_id: \"bundle_1988\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608230   nanos: 137574195 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001338144C610> and <keras.engine.input_layer.InputLayer object at 0x00000133803A69D0>).\" instruction_id: \"bundle_1990\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608230   nanos: 163576364 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000014B7E43E6D0> and <keras.engine.input_layer.InputLayer object at 0x0000014B7D0E5D90>).\" instruction_id: \"bundle_1989\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608235   nanos: 327245235 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000002729E55B340> and <keras.engine.input_layer.InputLayer object at 0x000002729E4C8040>).\" instruction_id: \"bundle_1991\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608235   nanos: 445342540 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000014B0306A550> and <keras.engine.input_layer.InputLayer object at 0x0000014B0301A220>).\" instruction_id: \"bundle_1989\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608235   nanos: 452963829 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001DD842C2A60> and <keras.engine.input_layer.InputLayer object at 0x000001DD84272730>).\" instruction_id: \"bundle_1988\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608235   nanos: 545285224 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000013385E29790> and <keras.engine.input_layer.InputLayer object at 0x0000013385D88460>).\" instruction_id: \"bundle_1990\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608236   nanos: 468623876 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1991\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608236   nanos: 556980133 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1988\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608236   nanos: 569981813 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1989\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608236   nanos: 699146032 } message: \"Couldn\\'t find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\" instruction_id: \"bundle_1990\" transform_id: \"ReadFromTFRecordToArrow[eval][0]/RawRecordBeamSource/ReadRawRecords/ReadFromTFRecord[0]/Read/SDFBoundedSourceReader/ParDo(SDFBoundedSourceDoFn)/Process\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\apache_beam\\\\io\\\\tfrecordio.py:59\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608243   nanos: 453213214 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000014B0AA30670> and <keras.engine.input_layer.InputLayer object at 0x0000014B0AA3A250>).\" instruction_id: \"bundle_2013\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608243   nanos: 470215797 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000272A5F166D0> and <keras.engine.input_layer.InputLayer object at 0x00000272A5F24A30>).\" instruction_id: \"bundle_2015\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608243   nanos: 488215446 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001338E81F730> and <keras.engine.input_layer.InputLayer object at 0x000001338D7D8370>).\" instruction_id: \"bundle_2014\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608243   nanos: 509213447 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001DD8CCBCF10> and <keras.engine.input_layer.InputLayer object at 0x000001DD8BC85F70>).\" instruction_id: \"bundle_2012\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608248   nanos: 860215902 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000014B1031BF40> and <keras.engine.input_layer.InputLayer object at 0x0000014B0AA8BBB0>).\" instruction_id: \"bundle_2013\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608248   nanos: 975169897 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000272AA844550> and <keras.engine.input_layer.InputLayer object at 0x00000272A6F44C10>).\" instruction_id: \"bundle_2015\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608248   nanos: 974169492 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000133930D3280> and <keras.engine.input_layer.InputLayer object at 0x000001338E7FCC10>).\" instruction_id: \"bundle_2014\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608249   nanos: 131926059 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001DD905A1A60> and <keras.engine.input_layer.InputLayer object at 0x000001DD8CC98C70>).\" instruction_id: \"bundle_2012\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608255   nanos: 979084253 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000014B14C2CE20> and <keras.engine.input_layer.InputLayer object at 0x0000014B14BCA7F0>).\" instruction_id: \"bundle_2025\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608256   nanos: 145417690 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000133979EAEE0> and <keras.engine.input_layer.InputLayer object at 0x00000133979898B0>).\" instruction_id: \"bundle_2026\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608256   nanos: 207417011 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000272B0144FA0> and <keras.engine.input_layer.InputLayer object at 0x00000272B00D66A0>).\" instruction_id: \"bundle_2027\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608256   nanos: 250823974 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001DD95FDF850> and <keras.engine.input_layer.InputLayer object at 0x000001DD95E69BB0>).\" instruction_id: \"bundle_2024\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608263   nanos: 839137554 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001339D528CA0> and <keras.engine.input_layer.InputLayer object at 0x000001339C400D90>).\" instruction_id: \"bundle_2038\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608263   nanos: 817121505 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000272B5C936A0> and <keras.engine.input_layer.InputLayer object at 0x00000272B4B71E80>).\" instruction_id: \"bundle_2039\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608263   nanos: 872720956 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001DD9B9BB6D0> and <keras.engine.input_layer.InputLayer object at 0x000001DD9A8927C0>).\" instruction_id: \"bundle_2036\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608263   nanos: 953179121 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000014B1A774520> and <keras.engine.input_layer.InputLayer object at 0x0000014B19652D90>).\" instruction_id: \"bundle_2037\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608270   nanos: 134822845 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x0000014B1F0186D0> and <keras.engine.input_layer.InputLayer object at 0x0000014B1A74AFD0>).\" instruction_id: \"bundle_2037\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-11\" \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608270   nanos: 131826400 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000272BA575850> and <keras.engine.input_layer.InputLayer object at 0x00000272B4C97FD0>).\" instruction_id: \"bundle_2039\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608270   nanos: 206823825 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x000001DDA02A9850> and <keras.engine.input_layer.InputLayer object at 0x000001DD9B991EE0>).\" instruction_id: \"bundle_2036\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-12\" \n",
      "WARNING:apache_beam.runners.portability.local_job_service:Worker: severity: WARN timestamp {   seconds: 1729608270   nanos: 203828573 } message: \"Inconsistent references when loading the checkpoint into this object graph. For example, in the saved checkpoint object, `model.layer.weight` and `model.layer_copy.weight` reference the same variable, while in the current object these are two different variables. The referenced variables are:(<keras.saving.saved_model.load.TensorFlowTransform>TransformFeaturesLayer object at 0x00000133A1DD5E20> and <keras.engine.input_layer.InputLayer object at 0x000001339D513C40>).\" instruction_id: \"bundle_2038\" log_location: \"C:\\\\Users\\\\Lenovo\\\\anaconda3\\\\envs\\\\mlops-attrition\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\checkpoint\\\\restore.py:84\" thread: \"Thread-13\" \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\envs\\mlops-attrition\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lenovo\\anaconda3\\envs\\mlops-attrition\\lib\\site-packages\\tensorflow_model_analysis\\writers\\metrics_plots_and_validations_writer.py:110: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    }
   ],
   "source": [
    "components = init_components(\n",
    "    data_dir=DATA_ROOT,\n",
    "    transform_module=TRANSFORM_MODULE_FILE,\n",
    "    training_module=TRAINER_MODULE_FILE,\n",
    "    training_steps=5000,\n",
    "    eval_steps=1000,\n",
    "    serving_model_dir=serving_model_dir\n",
    ")\n",
    "\n",
    "pipeline = init_local_pipeline(components, pipeline_root)\n",
    "BeamDagRunner().run(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops attrition",
   "language": "python",
   "name": "mlops-attrition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
